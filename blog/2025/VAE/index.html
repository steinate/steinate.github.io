<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>变分自编码器(VAE)原理与扩散模型的关系 | 技术博客</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.8/dist/chart.umd.min.js"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <!-- Tailwind 配置 -->
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        primary: '#8B5CF6', // 紫色作为主色调，与VAE主题相符
                        secondary: '#3B82F6', // 蓝色作为辅助色，与扩散模型呼应
                        dark: '#1E293B',
                        light: '#F8FAFC'
                    },
                    fontFamily: {
                        sans: ['Inter', 'system-ui', 'sans-serif'],
                        serif: ['Georgia', 'serif'],
                        mono: ['Consolas', 'Monaco', 'monospace']
                    },
                }
            }
        }
    </script>
    
    <style type="text/tailwindcss">
        @layer utilities {
            .content-auto {
                content-visibility: auto;
            }
            .text-balance {
                text-wrap: balance;
            }
            .math-display {
                @apply my-6;
            }
            .section-fade {
                @apply opacity-0 transform translate-y-4 transition-all duration-700 ease-out;
            }
            .section-visible {
                @apply opacity-100 transform translate-y-0;
            }
            .comparison-row {
                @apply border-b border-gray-200 last:border-0;
            }
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800 font-sans">
    <!-- 导航栏 -->
    <header class="sticky top-0 z-50 bg-white/90 backdrop-blur-sm shadow-sm transition-all duration-300">
        <div class="container mx-auto px-4 py-4 flex justify-between items-center">
            <div class="flex items-center space-x-2">
                <i class="fa fa-cube text-primary text-2xl"></i>
                <h1 class="text-xl font-bold text-dark">VAE与扩散模型</h1>
            </div>
            
            <!-- 桌面导航 -->
            <nav class="hidden md:flex items-center space-x-6">
                <a href="#intro" class="text-gray-600 hover:text-primary transition-colors">VAE简介</a>
                <a href="#theory" class="text-gray-600 hover:text-primary transition-colors">理论推导</a>
                <a href="#training" class="text-gray-600 hover:text-primary transition-colors">训练过程</a>
                <a href="#relation" class="text-gray-600 hover:text-secondary transition-colors">与扩散模型关系</a>
                <a href="#comparison" class="text-gray-600 hover:text-primary transition-colors">对比分析</a>
                <a href="#summary" class="text-gray-600 hover:text-primary transition-colors">总结</a>
            </nav>
            
            <!-- 移动端菜单按钮 -->
            <button id="menuBtn" class="md:hidden text-gray-600 hover:text-primary">
                <i class="fa fa-bars text-xl"></i>
            </button>
        </div>
        
        <!-- 移动端导航菜单 -->
        <div id="mobileMenu" class="hidden md:hidden bg-white border-t border-gray-200">
            <div class="container mx-auto px-4 py-2 flex flex-col space-y-3">
                <a href="#intro" class="py-2 text-gray-600 hover:text-primary transition-colors">VAE简介</a>
                <a href="#theory" class="py-2 text-gray-600 hover:text-primary transition-colors">理论推导</a>
                <a href="#training" class="py-2 text-gray-600 hover:text-primary transition-colors">训练过程</a>
                <a href="#relation" class="py-2 text-gray-600 hover:text-secondary transition-colors">与扩散模型关系</a>
                <a href="#comparison" class="py-2 text-gray-600 hover:text-primary transition-colors">对比分析</a>
                <a href="#summary" class="py-2 text-gray-600 hover:text-primary transition-colors">总结</a>
            </div>
        </div>
    </header>

    <!-- 主内容 -->
    <main class="container mx-auto px-4 py-8 md:py-12">
        <!-- 博客标题区域 -->
        <div class="text-center max-w-4xl mx-auto mb-16 section-fade">
            <span class="inline-block px-3 py-1 bg-purple-100 text-primary rounded-full text-sm font-medium mb-4">
                深度学习 · 生成模型
            </span>
            <h1 class="text-4xl md:text-5xl font-bold mb-6 text-dark leading-tight">
                变分自编码器(VAE)的原理推导<br class="md:hidden">与扩散模型的联系
            </h1>
            <p class="text-gray-600 text-lg md:text-xl mb-8 text-balance">
                解析VAE的数学基础，比较两种主流生成模型的异同
            </p>
            <div class="flex items-center justify-center space-x-4">
                <img src="https://picsum.photos/id/1005/40/40" alt="作者头像" class="w-10 h-10 rounded-full">
                <div class="text-left">
                    <p class="font-medium">AI技术研究员</p>
                    <p class="text-sm text-gray-500">发布于 2023年11月2日 · 阅读时间: 30分钟</p>
                </div>
            </div>
        </div>

        <!-- 目录 -->
        <div class="max-w-4xl mx-auto mb-16 bg-white rounded-xl shadow-sm p-6 border border-gray-100 section-fade">
            <h2 class="text-xl font-bold mb-4 flex items-center">
                <i class="fa fa-list-ul text-primary mr-2"></i> 文章目录
            </h2>
            <ul class="space-y-2 text-gray-700">
                <li class="flex items-center">
                    <i class="fa fa-angle-right text-primary mr-2"></i>
                    <a href="#intro" class="hover:text-primary transition-colors">变分自编码器(VAE)简介</a>
                </li>
                <li class="flex items-center">
                    <i class="fa fa-angle-right text-primary mr-2"></i>
                    <a href="#theory" class="hover:text-primary transition-colors">VAE的理论推导</a>
                </li>
                <li class="flex items-center">
                    <i class="fa fa-angle-right text-primary mr-2"></i>
                    <a href="#training" class="hover:text-primary transition-colors">VAE的训练过程</a>
                </li>
                <li class="flex items-center">
                    <i class="fa fa-angle-right text-primary mr-2"></i>
                    <a href="#relation" class="hover:text-secondary transition-colors">VAE与扩散模型的内在联系</a>
                </li>
                <li class="flex items-center">
                    <i class="fa fa-angle-right text-primary mr-2"></i>
                    <a href="#comparison" class="hover:text-primary transition-colors">VAE与扩散模型的对比分析</a>
                </li>
                <li class="flex items-center">
                    <i class="fa fa-angle-right text-primary mr-2"></i>
                    <a href="#summary" class="hover:text-primary transition-colors">总结与展望</a>
                </li>
            </ul>
        </div>

        <!-- 正文内容 -->
        <div class="max-w-4xl mx-auto space-y-12">
            <!-- 1. VAE简介 -->
            <section id="intro" class="section-fade">
                <div class="flex items-center mb-6">
                    <div class="w-10 h-10 rounded-full bg-primary/10 flex items-center justify-center mr-4">
                        <i class="fa fa-info text-primary"></i>
                    </div>
                    <h2 class="text-3xl font-bold text-dark">变分自编码器(VAE)简介</h2>
                </div>
                
                <p class="text-gray-700 mb-6 leading-relaxed">
                    变分自编码器(Variational Autoencoder, VAE)是由Kingma和Welling在2013年提出的一种生成模型，它结合了自编码器的架构和变分推断的数学原理。VAE不仅能够像普通自编码器一样进行数据压缩和重建，还能够学习数据的潜在概率分布，从而具备生成新数据的能力。
                </p>
                
                <div class="bg-white rounded-xl shadow-sm p-6 border border-gray-100 mb-8">
                    <h3 class="text-xl font-semibold mb-4 text-primary">VAE的核心思想</h3>
                    <p class="text-gray-700 mb-4">
                        VAE的核心思想是学习一个潜在变量模型(latent variable model)来表示数据分布。对于给定的观测数据\( \mathbf{x} \)，我们假设它是由一些不可观测的潜在变量\( \mathbf{z} \)生成的，即：
                    </p>
                    <div class="math-display">
                        \[
                        p(\mathbf{x}) = \int p(\mathbf{x} | \mathbf{z}) p(\mathbf{z}) d\mathbf{z}
                        \]
                    </div>
                    <p class="text-gray-700">
                        其中\( p(\mathbf{z}) \)是潜在变量的先验分布，\( p(\mathbf{x} | \mathbf{z}) \)是生成模型，描述了如何从潜在变量生成观测数据。
                    </p>
                </div>
                
                <div class="my-8">
                    <img src="https://picsum.photos/id/180/800/400" alt="VAE架构示意图" class="w-full h-auto rounded-lg shadow-sm">
                    <p class="text-sm text-gray-500 text-center mt-2">图1: VAE架构示意图（编码器-解码器结构）</p>
                </div>
                
                <p class="text-gray-700 mb-6 leading-relaxed">
                    与传统自编码器相比，VAE有两个关键区别：
                </p>
                
                <div class="grid md:grid-cols-2 gap-6 mb-6">
                    <div class="bg-purple-50 p-6 rounded-lg border border-purple-100">
                        <h3 class="text-lg font-semibold text-primary mb-3 flex items-center">
                            <i class="fa fa-random mr-2"></i> 概率编码器
                        </h3>
                        <p class="text-gray-700">
                            VAE的编码器不是直接输出潜在向量，而是输出潜在变量的概率分布参数（均值和方差），表示输入数据在潜在空间中的分布。
                        </p>
                    </div>
                    
                    <div class="bg-blue-50 p-6 rounded-lg border border-blue-100">
                        <h3 class="text-lg font-semibold text-secondary mb-3 flex items-center">
                            <i class="fa fa-calculator mr-2"></i> 变分推断
                        </h3>
                        <p class="text-gray-700">
                            VAE使用变分推断来近似计算难以直接求解的后验分布，通过优化证据下界(ELBO)来训练模型，兼顾了重建精度和潜在分布的合理性。
                        </p>
                    </div>
                </div>
                
                <p class="text-gray-700 leading-relaxed">
                    这些特点使得VAE能够生成全新的数据样本，而不仅仅是重建输入数据，这也是VAE作为生成模型的核心价值所在。
                </p>
            </section>

            <!-- 2. VAE的理论推导 -->
            <section id="theory" class="section-fade">
                <div class="flex items-center mb-6">
                    <div class="w-10 h-10 rounded-full bg-primary/10 flex items-center justify-center mr-4">
                        <i class="fa fa-pencil text-primary"></i>
                    </div>
                    <h2 class="text-3xl font-bold text-dark">VAE的理论推导</h2>
                </div>
                
                <p class="text-gray-700 mb-6 leading-relaxed">
                    VAE的理论基础建立在贝叶斯推断和变分方法之上。下面我们将详细推导VAE的核心公式和目标函数。
                </p>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">2.1 问题定义</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    我们的目标是学习数据\( \mathbf{x} \)的概率分布\( p(\mathbf{x}) \)，以便能够从中采样生成新的数据。根据贝叶斯定理，我们有：
                </p>
                
                <div class="math-display">
                    \[
                    p(\mathbf{x}) = \int p(\mathbf{x} | \mathbf{z}) p(\mathbf{z}) d\mathbf{z}
                    \]
                </div>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    其中：
                    <ul class="list-disc list-inside ml-4 mt-2 space-y-1 text-gray-700">
                        <li>\( p(\mathbf{z}) \)是潜在变量\( \mathbf{z} \)的先验分布，通常假设为标准正态分布\( \mathcal{N}(\mathbf{0}, \mathbf{I}) \)</li>
                        <li>\( p(\mathbf{x} | \mathbf{z}) \)是生成模型，描述了如何从潜在变量生成观测数据</li>
                    </ul>
                </p>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    为了计算这个边际分布，我们需要知道后验分布\( p(\mathbf{z} | \mathbf{x}) \)，但在大多数情况下，这个后验分布难以直接计算。VAE通过变分推断来解决这个问题。
                </p>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">2.2 变分推断与证据下界(ELBO)</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    变分推断的核心思想是使用一个易于处理的近似分布\( q(\mathbf{z} | \mathbf{x}) \)来逼近真实的后验分布\( p(\mathbf{z} | \mathbf{x}) \)。我们可以通过最小化这两个分布之间的KL散度来实现：
                </p>
                
                <div class="math-display">
                    \[
                    D_{\text{KL}}(q(\mathbf{z} | \mathbf{x}) \| p(\mathbf{z} | \mathbf{x})) = \mathbb{E}_{q} \left[ \log \frac{q(\mathbf{z} | \mathbf{x})}{p(\mathbf{z} | \mathbf{x})} \right]
                    \]
                </div>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    根据贝叶斯定理\( p(\mathbf{z} | \mathbf{x}) = \frac{p(\mathbf{x} | \mathbf{z}) p(\mathbf{z})}{p(\mathbf{x})} \)，代入上式可得：
                </p>
                
                <div class="math-display">
                    \[
                    D_{\text{KL}}(q(\mathbf{z} | \mathbf{x}) \| p(\mathbf{z} | \mathbf{x})) = \mathbb{E}_{q} \left[ \log q(\mathbf{z} | \mathbf{x}) \right] - \mathbb{E}_{q} \left[ \log p(\mathbf{x} | \mathbf{z}) p(\mathbf{z}) \right] + \log p(\mathbf{x})
                    \]
                </div>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    整理后得到：
                </p>
                
                <div class="math-display">
                    \[
                    \log p(\mathbf{x}) = -D_{\text{KL}}(q(\mathbf{z} | \mathbf{x}) \| p(\mathbf{z} | \mathbf{x})) + \left( \mathbb{E}_{q} \left[ \log p(\mathbf{x} | \mathbf{z}) \right] - D_{\text{KL}}(q(\mathbf{z} | \mathbf{x}) \| p(\mathbf{z})) \right)
                    \]
                </div>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    由于KL散度总是非负的，我们得到对数似然的一个下界：
                </p>
                
                <div class="math-display">
                    \[
                    \log p(\mathbf{x}) \geq \mathbb{E}_{q} \left[ \log p(\mathbf{x} | \mathbf{z}) \right] - D_{\text{KL}}(q(\mathbf{z} | \mathbf{x}) \| p(\mathbf{z})) =: \mathcal{L}(\mathbf{x}; \theta, \phi)
                    \]
                </div>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    这个下界被称为证据下界(Evidence Lower Bound, ELBO)。VAE的训练目标就是最大化这个下界。ELBO由两个部分组成：
                </p>
                
                <ol class="list-decimal list-inside space-y-2 text-gray-700 mb-6 ml-2">
                    <li><strong>重建损失</strong>：\( \mathbb{E}_{q} \left[ \log p(\mathbf{x} | \mathbf{z}) \right] \)，衡量模型从潜在变量重建输入数据的能力</li>
                    <li><strong>正则化项</strong>：\( -D_{\text{KL}}(q(\mathbf{z} | \mathbf{x}) \| p(\mathbf{z})) \)，确保近似后验分布接近先验分布，使潜在空间具有良好的结构</li>
                </ol>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">2.3 分布假设与参数化</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    为了使模型可计算，VAE对分布形式做出了特定假设：
                </p>
                
                <div class="bg-white p-6 rounded-lg shadow-sm border border-gray-100 mb-6">
                    <h4 class="font-semibold mb-3 text-primary">分布假设</h4>
                    <1. 先验分布\( p(\mathbf{z}) \)：通常选择标准正态分布
                        \[
                        p(\mathbf{z}) = \mathcal{N}(\mathbf{z}; \mathbf{0}, \mathbf{I})
                        \]
                    </p>
                    <p class="mb-3">2. 近似后验分布\( q(\mathbf{z} | \mathbf{x}) \)：选择对角协方差的正态分布，其参数由编码器网络输出
                        \[
                        q(\mathbf{z} | \mathbf{x}; \phi) = \mathcal{N}(\mathbf{z}; \boldsymbol{\mu}(\mathbf{x}; \phi), \text{diag}(\boldsymbol{\sigma}^2(\mathbf{x}; \phi)))
                        \]
                        其中\( \boldsymbol{\mu} \)和\( \boldsymbol{\sigma}^2 \)是由神经网络参数化的均值和方差。
                    </p>
                    <p>3. 生成分布\( p(\mathbf{x} | \mathbf{z}) \)：对于实值数据（如图像），通常选择正态分布；对于二进制数据，选择伯努利分布
                        \[
                        p(\mathbf{x} | \mathbf{z}; \theta) = \mathcal{N}(\mathbf{x}; \boldsymbol{\mu}_\theta(\mathbf{z}), \sigma^2 \mathbf{I})
                        \]
                    </p>
                </div>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">2.4 KL散度的计算</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    当\( p(\mathbf{z}) \)和\( q(\mathbf{z} | \mathbf{x}) \)都是正态分布时，KL散度有闭式解。对于\( p(\mathbf{z}) = \mathcal{N}(\mathbf{0}, \mathbf{I}) \)和\( q(\mathbf{z} | \mathbf{x}) = \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\sigma}^2 \mathbf{I}) \)，KL散度为：
                </p>
                
                <div class="math-display">
                    \[
                    D_{\text{KL}}(q \| p) = \frac{1}{2} \sum_{i=1}^d \left( \mu_i^2 + \sigma_i^2 - \log \sigma_i^2 - 1 \right)
                    \]
                </div>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    其中d是潜在空间的维度。这个公式可以直接计算，无需采样，大大简化了VAE的训练。
                </p>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">2.5 重参数化技巧</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    为了计算重建损失\( \mathbb{E}_{q} \left[ \log p(\mathbf{x} | \mathbf{z}) \right] \)，我们需要从\( q(\mathbf{z} | \mathbf{x}) \)中采样\( \mathbf{z} \)。然而，采样操作是不可导的，这给反向传播带来了困难。
                </p>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    VAE通过重参数化技巧(reparameterization trick)解决了这个问题。具体来说，我们将采样过程表示为：
                </p>
                
                <div class="math-display">
                    \[
                    \mathbf{z} = \boldsymbol{\mu} + \boldsymbol{\sigma} \odot \boldsymbol{\epsilon}, \quad \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})
                    \]
                </div>
                
                <p class="text-gray-700 leading-relaxed">
                    其中\( \odot \)表示元素-wise乘法。通过这种方式，随机性被转移到了\( \boldsymbol{\epsilon} \)上，而\( \mathbf{z} \)相对于\( \boldsymbol{\mu} \)和\( \boldsymbol{\sigma} \)是可导的。这使得我们可以使用梯度下降法来优化模型参数。
                </p>
                
                <div class="my-8">
                    <img src="https://picsum.photos/id/366/800/300" alt="重参数化技巧示意图" class="w-full h-auto rounded-lg shadow-sm">
                    <p class="text-sm text-gray-500 text-center mt-2">图2: 重参数化技巧示意图，将随机性与参数解耦</p>
                </div>
            </section>

            <!-- 3. VAE的训练过程 -->
            <section id="training" class="section-fade">
                <div class="flex items-center mb-6">
                    <div class="w-10 h-10 rounded-full bg-primary/10 flex items-center justify-center mr-4">
                        <i class="fa fa-cogs text-primary"></i>
                    </div>
                    <h2 class="text-3xl font-bold text-dark">VAE的训练过程</h2>
                </div>
                
                <p class="text-gray-700 mb-6 leading-relaxed">
                    基于前面的理论推导，VAE的训练过程可以总结为以下步骤，其核心是最大化证据下界ELBO。
                </p>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">3.1 网络结构</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    VAE由两个主要部分组成：编码器(Encoder)和解码器(Decoder)。
                </p>
                
                <div class="grid md:grid-cols-2 gap-6 mb-8">
                    <div class="bg-white p-6 rounded-lg shadow-sm border border-gray-100">
                        <h4 class="font-semibold mb-3 text-primary flex items-center">
                            <i class="fa fa-compress mr-2"></i> 编码器
                        </h4>
                        <p class="text-gray-700 mb-3">
                            编码器接收输入数据\( \mathbf{x} \)，输出潜在分布\( q(\mathbf{z} | \mathbf{x}) \)的参数：
                        </p>
                        <ul class="list-disc list-inside space-y-1 text-gray-700 ml-2">
                            <li>均值向量\( \boldsymbol{\mu} = f_\phi(\mathbf{x}) \)</li>
                            <li>方差向量\( \boldsymbol{\sigma}^2 = g_\phi(\mathbf{x}) \)（通常输出的是\( \log \boldsymbol{\sigma}^2 \)，以便确保方差为正）</li>
                        </ul>
                        <p class="text-gray-700 mt-3">
                            其中\( f_\phi \)和\( g_\phi \)是由参数\( \phi \)表示的神经网络。
                        </p>
                    </div>
                    
                    <div class="bg-white p-6 rounded-lg shadow-sm border border-gray-100">
                        <h4 class="font-semibold mb-3 text-primary flex items-center">
                            <i class="fa fa-expand mr-2"></i> 解码器
                        </h4>
                        <p class="text-gray-700 mb-3">
                            解码器接收从潜在分布采样的\( \mathbf{z} \)，输出生成分布\( p(\mathbf{x} | \mathbf{z}) \)的参数：
                        </p>
                        <ul class="list-disc list-inside space-y-1 text-gray-700 ml-2">
                            <li>对于实值数据：均值\( \boldsymbol{\mu}_\theta = h_\theta(\mathbf{z}) \)（方差可以固定或学习）</li>
                            <li>对于二进制数据：伯努利分布的概率\( \boldsymbol{\pi}_\theta = h_\theta(\mathbf{z}) \)</li>
                        </ul>
                        <p class="text-gray-700 mt-3">
                            其中\( h_\theta \)是由参数\( \theta \)表示的神经网络。
                        </p>
                    </div>
                </div>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">3.2 训练算法</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    VAE的训练算法如下：
                </p>
                
                <div class="bg-gray-50 p-6 rounded-lg border border-gray-200 mb-8">
                    <ol class="list-decimal list-inside space-y-4 text-gray-700">
                        <li>
                            <strong>初始化</strong>：随机初始化编码器参数\( \phi \)和解码器参数\( \theta \)
                        </li>
                        <li>
                            <strong>对于每个训练样本\( \mathbf{x} \)</strong>：
                            <ol class="list-lower-alpha list-inside ml-6 mt-2 space-y-3">
                                <li>
                                    <strong>编码</strong>：通过编码器计算潜在分布的参数
                                    \[
                                    \boldsymbol{\mu}, \log \boldsymbol{\sigma}^2 = \text{Encoder}(\mathbf{x}; \phi)
                                    \]
                                </li>
                                <li>
                                    <strong>重参数化采样</strong>：
                                    \[
                                    \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}), \quad \mathbf{z} = \boldsymbol{\mu} + \exp(\log \boldsymbol{\sigma}^2 / 2) \odot \boldsymbol{\epsilon}
                                    \]
                                </li>
                                <li>
                                    <strong>解码</strong>：通过解码器计算生成分布的参数
                                    \[
                                    \hat{\mathbf{x}} = \text{Decoder}(\mathbf{z}; \theta)
                                    \]
                                </li>
                                <li>
                                    <strong>计算损失</strong>：
                                    <ul class="list-disc list-inside ml-6 mt-2 space-y-1">
                                        <li>重建损失：\( \mathcal{L}_{\text{recon}} = -\log p(\mathbf{x} | \mathbf{z}; \theta) \)</li>
                                        <li>KL散度：\( \mathcal{L}_{\text{KL}} = D_{\text{KL}}(q(\mathbf{z} | \mathbf{x}) \| p(\mathbf{z})) \)</li>
                                        <li>总损失：\( \mathcal{L} = \mathcal{L}_{\text{recon}} + \mathcal{L}_{\text{KL}} \)</li>
                                    </ul>
                                </li>
                                <li>
                                    <strong>参数更新</strong>：通过梯度下降最小化总损失\( \mathcal{L} \)，更新\( \phi \)和\( \theta \)
                                </li>
                            </ol>
                        </li>
                        <li>
                            <strong>重复</strong>：直到模型收敛
                        </li>
                    </ol>
                </div>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">3.3 生成新样本</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    训练完成后，生成新样本的过程非常简单：
                </p>
                
                <div class="bg-white p-6 rounded-lg shadow-sm border border-gray-100 mb-6">
                    <ol class="list-decimal list-inside space-y-3 text-gray-700">
                        <li>从先验分布中采样潜在变量：\( \mathbf{z} \sim p(\mathbf{z}) = \mathcal{N}(\mathbf{0}, \mathbf{I}) \)</li>
                        <li>将潜在变量输入解码器：\( \hat{\mathbf{x}} = \text{Decoder}(\mathbf{z}; \theta) \)</li>
                        <li>\( \hat{\mathbf{x}} \)即为生成的新样本（对于概率生成分布，可以直接取均值或再进行一次采样）</li>
                    </ol>
                </div>
                
                <div class="my-8">
                    <div class="grid grid-cols-2 md:grid-cols-4 gap-4">
                        <div class="bg-white p-2 rounded shadow-sm">
                            <img src="https://picsum.photos/id/1025/200/200?random=1" alt="VAE生成样本1" class="w-full h-auto rounded">
                        </div>
                        <div class="bg-white p-2 rounded shadow-sm">
                            <img src="https://picsum.photos/id/1025/200/200?random=2" alt="VAE生成样本2" class="w-full h-auto rounded">
                        </div>
                        <div class="bg-white p-2 rounded shadow-sm">
                            <img src="https://picsum.photos/id/1025/200/200?random=3" alt="VAE生成样本3" class="w-full h-auto rounded">
                        </div>
                        <div class="bg-white p-2 rounded shadow-sm">
                            <img src="https://picsum.photos/id/1025/200/200?random=4" alt="VAE生成样本4" class="w-full h-auto rounded">
                        </div>
                    </div>
                    <p class="text-sm text-gray-500 text-center mt-2">图3: VAE生成的样本示例</p>
                </div>
            </section>

            <!-- 4. VAE与扩散模型的内在联系 -->
            <section id="relation" class="section-fade">
                <div class="flex items-center mb-6">
                    <div class="w-10 h-10 rounded-full bg-secondary/10 flex items-center justify-center mr-4">
                        <i class="fa fa-link text-secondary"></i>
                    </div>
                    <h2 class="text-3xl font-bold text-dark">VAE与扩散模型的内在联系</h2>
                </div>
                
                <p class="text-gray-700 mb-6 leading-relaxed">
                    VAE和扩散模型(Diffusion Model)是两种重要的生成模型，尽管它们的实现方式有很大差异，但在理论基础和目标上存在深刻的内在联系。
                </p>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">4.1 共同的理论基础</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    VAE和扩散模型都建立在概率图模型和贝叶斯推断的基础上，都旨在学习数据的潜在概率分布。
                </p>
                
                <div class="bg-gradient-to-r from-purple-50 to-blue-50 p-6 rounded-lg border border-purple-100 mb-8">
                    <h4 class="font-semibold mb-3 text-dark">概率建模框架</h4>
                    <p class="text-gray-700 mb-4">
                        两种模型都可以纳入以下概率建模框架：
                    </p>
                    <div class="math-display">
                        \[
                        p(\mathbf{x}) = \int p(\mathbf{x} | \mathbf{z}) p(\mathbf{z}) d\mathbf{z}
                        \]
                    </div>
                    <p class="text-gray-700">
                        其中\( \mathbf{z} \)是潜在变量。对于VAE，\( \mathbf{z} \)是低维潜在向量；对于扩散模型，\( \mathbf{z} \)可以视为扩散过程中的噪声变量序列。
                    </p>
                </div>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">4.2 变分推断的统一视角</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    扩散模型可以被视为一种特殊的变分推断方法，其目标也是最大化证据下界ELBO，这与VAE的目标一致。
                </p>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    在扩散模型中，前向扩散过程定义了一个近似后验分布\( q(\mathbf{x}_{1:T} | \mathbf{x}_0) \)，而逆向过程则定义了生成模型\( p_\theta(\mathbf{x}_{0:T}) \)。扩散模型的训练目标可以表示为：
                </p>
                
                <div class="math-display">
                    \[
                    \mathcal{L} = \mathbb{E}_{q} \left[ \log \frac{p_\theta(\mathbf{x}_0, \mathbf{x}_{1:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \right]
                    \]
                </div>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    这与VAE的ELBO在形式上是相似的，都是对数联合概率与对数近似后验概率的期望差。
                </p>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">4.3 潜在变量的演化</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    两种模型都涉及潜在变量的演化过程，尽管方式不同：
                </p>
                
                <div class="grid md:grid-cols-2 gap-6 mb-8">
                    <div class="bg-purple-50 p-6 rounded-lg border border-purple-100">
                        <h4 class="font-semibold mb-3 text-primary">VAE的潜在变量</h4>
                        <p class="text-gray-700">
                            VAE使用单一的潜在变量\( \mathbf{z} \)来表示数据的抽象特征。从先验分布\( p(\mathbf{z}) \)到数据分布\( p(\mathbf{x}) \)的映射是通过解码器一次性完成的。
                        </p>
                    </div>
                    
                    <div class="bg-blue-50 p-6 rounded-lg border border-blue-100">
                        <h4 class="font-semibold mb-3 text-secondary">扩散模型的潜在变量</h4>
                        <p class="text-gray-700">
                            扩散模型使用一系列潜在变量\( \mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_T \)，通过一个逐步的过程从噪声（先验）演化到数据。每个步骤只依赖于前一个步骤，形成一个马尔可夫链。
                        </p>
                    </div>
                </div>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">4.4 连续极限下的联系</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    当扩散模型的步骤数T趋向于无穷大时，可以将其视为一个连续时间的随机过程。在这种情况下，扩散模型与VAE的联系更加明显。
                </p>
                
                <p class="text-gray-700 leading-relaxed">
                    研究表明，在连续极限下，扩散模型的ELBO可以表示为一个积分形式，与VAE的ELBO具有相似的解释：一部分是数据重建项，另一部分是正则化项，确保潜在过程的演化符合先验假设。
                </p>
                
                <div class="my-8">
                    <canvas id="modelRelationshipChart" width="400" height="250"></canvas>
                    <p class="text-sm text-gray-500 text-center mt-2">图4: VAE与扩散模型在生成模型谱系中的位置</p>
                </div>
            </section>

            <!-- 5. VAE与扩散模型的对比分析 -->
            <section id="comparison" class="section-fade">
                <div class="flex items-center mb-6">
                    <div class="w-10 h-10 rounded-full bg-primary/10 flex items-center justify-center mr-4">
                        <i class="fa fa-balance-scale text-primary"></i>
                    </div>
                    <h2 class="text-3xl font-bold text-dark">VAE与扩散模型的对比分析</h2>
                </div>
                
                <p class="text-gray-700 mb-6 leading-relaxed">
                    尽管VAE和扩散模型有共同的理论基础，但它们在实际应用中表现出不同的特点。以下从多个维度对两者进行对比分析。
                </p>
                
                <div class="overflow-x-auto mb-8">
                    <table class="w-full bg-white rounded-lg shadow-sm border border-gray-200">
                        <thead>
                            <tr class="bg-gray-50 border-b border-gray-200">
                                <th class="py-4 px-6 text-left text-gray-700 font-semibold">对比维度</th>
                                <th class="py-4 px-6 text-left text-primary font-semibold">变分自编码器(VAE)</th>
                                <th class="py-4 px-6 text-left text-secondary font-semibold">扩散模型(Diffusion Model)</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="comparison-row">
                                <td class="py-4 px-6 text-gray-700 font-medium">生成质量</td>
                                <td class="py-4 px-6 text-gray-700">
                                    中等，生成样本通常较为模糊，细节不够丰富
                                </td>
                                <td class="py-4 px-6 text-gray-700">
                                    高，能够生成高度逼真、细节丰富的样本，在图像生成任务中表现优异
                                </td>
                            </tr>
                            <tr class="comparison-row">
                                <td class="py-4 px-6 text-gray-700 font-medium">训练稳定性</td>
                                <td class="py-4 px-6 text-gray-700">
                                    较高，损失函数设计稳定，不易出现训练不稳定问题
                                </td>
                                <td class="py-4 px-6 text-gray-700">
                                    高，训练过程稳定，没有GAN等模型的模式崩溃问题
                                </td>
                            </tr>
                            <tr class="comparison-row">
                                <td class="py-4 px-6 text-gray-700 font-medium">采样速度</td>
                                <td class="py-4 px-6 text-gray-700">
                                    快，只需一次前向传播即可生成样本
                                </td>
                                <td class="py-4 px-6 text-gray-700">
                                    慢，需要T步迭代（通常1000步左右）才能生成样本，尽管已有加速方法
                                </td>
                            </tr>
                            <tr class="comparison-row">
                                <td class="py-4 px-6 text-gray-700 font-medium">潜在空间结构</td>
                                <td class="py-4 px-6 text-gray-700">
                                    具有良好的连续性和可解释性，支持插值等操作
                                </td>
                                <td class="py-4 px-6 text-gray-700">
                                    潜在空间结构复杂，通常不直接支持插值等操作
                                </td>
                            </tr>
                            <tr class="comparison-row">
                                <td class="py-4 px-6 text-gray-700 font-medium">计算复杂度</td>
                                <td class="py-4 px-6 text-gray-700">
                                    低，模型参数较少，训练和推理成本低
                                </td>
                                <td class="py-4 px-6 text-gray-700">
                                    高，模型通常较大，训练和推理需要更多计算资源
                                </td>
                            </tr>
                            <tr class="comparison-row">
                                <td class="py-4 px-6 text-gray-700 font-medium">灵活性</td>
                                <td class="py-4 px-6 text-gray-700">
                                    中等，修改和扩展相对容易，但生成质量提升空间有限
                                </td>
                                <td class="py-4 px-6 text-gray-700">
                                    高，易于与其他技术结合（如文本引导），扩展能力强
                                </td>
                            </tr>
                            <tr class="comparison-row">
                                <td class="py-4 px-6 text-gray-700 font-medium">适用场景</td>
                                <td class="py-4 px-6 text-gray-700">
                                    快速生成、潜在空间分析、降维、异常检测等
                                </td>
                                <td class="py-4 px-6 text-gray-700">
                                    高质量图像生成、精细编辑、超分辨率重建等
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">5.1 生成质量的差异原因</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    扩散模型生成质量通常优于VAE的主要原因包括：
                </p>
                
                <ul class="list-disc list-inside space-y-2 text-gray-700 mb-6 ml-2">
                    <li><strong>建模能力</strong>：扩散模型通过多步过程逐步细化生成结果，能够捕捉更精细的细节</li>
                    <li><strong>目标函数</strong>：扩散模型的损失函数更直接地优化了数据分布，而VAE则优化的是下界</li>
                    <li><strong>先验分布</strong>：扩散模型使用的噪声先验可能比VAE的简单高斯先验更适合建模复杂数据</li>
                </ul>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">5.2 模型融合与杂交方法</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    研究人员已经开始探索融合VAE和扩散模型优势的杂交方法：
                </p>
                
                <div class="bg-white p-6 rounded-lg shadow-sm border border-gray-100 mb-6">
                    <ol class="list-decimal list-inside space-y-3 text-gray-700">
                        <li>
                            <strong>潜在扩散模型(Latent Diffusion Models)</strong>：如Stable Diffusion，在VAE的潜在空间中进行扩散过程，结合了VAE的效率和扩散模型的生成质量
                        </li>
                        <li>
                            <strong>VAE引导的扩散模型</strong>：使用VAE的潜在表示来引导扩散过程，加速收敛并提高生成质量
                        </li>
                        <li>
                            <strong>扩散增强的VAE</strong>：在VAE的解码器之后添加一个扩散过程作为后处理步骤，提高生成样本的质量
                        </li>
                    </ol>
                </div>
                
                <p class="text-gray-700 leading-relaxed">
                    这些杂交模型已经取得了显著成功，例如Stable Diffusion在保持高质量生成的同时，大大降低了扩散模型的计算成本，使其能够在普通GPU上运行。
                </p>
            </section>

            <!-- 6. 总结与展望 -->
            <section id="summary" class="section-fade">
                <div class="flex items-center mb-6">
                    <div class="w-10 h-10 rounded-full bg-primary/10 flex items-center justify-center mr-4">
                        <i class="fa fa-flag-checkered text-primary"></i>
                    </div>
                    <h2 class="text-3xl font-bold text-dark">总结与展望</h2>
                </div>
                
                <p class="text-gray-700 mb-6 leading-relaxed">
                    VAE和扩散模型作为两种重要的生成模型，各自在生成式AI领域发挥着重要作用。通过对它们的原理和关系的深入分析，我们可以更好地理解生成模型的发展脉络和未来方向。
                </p>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">6.1 VAE的贡献与局限</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    VAE的主要贡献在于：
                </p>
                
                <ul class="list-disc list-inside space-y-2 text-gray-700 mb-4 ml-2">
                    <li>将变分推断与神经网络结合，提供了一种 principled 的生成模型训练方法</li>
                    <li>引入重参数化技巧，解决了采样过程的可导性问题</li>
                    <li>学习到的潜在空间具有良好的连续性和可解释性，支持各种潜在空间操作</li>
                    <li>训练稳定，实现简单，为后续生成模型的发展奠定了基础</li>
                </ul>
                
                <p class="text-gray-700 mb-6 leading-relaxed">
                    同时，VAE也存在一些局限：
                </p>
                
                <ul class="list-disc list-inside space-y-2 text-gray-700 mb-6 ml-2">
                    <li>生成质量相对较低，样本通常较为模糊</li>
                    <li>ELBO是对数似然的下界，可能无法充分捕捉数据分布的细节</li>
                    <li>高斯假设可能限制了模型对复杂数据分布的表达能力</li>
                </ul>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">6.2 扩散模型的优势与挑战</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    扩散模型的主要优势包括：
                </p>
                
                <ul class="list-disc list-inside space-y-2 text-gray-700 mb-4 ml-2">
                    <li>生成质量高，能够生成高度逼真、细节丰富的样本</li>
                    <li>训练过程稳定，不存在模式崩溃等问题</li>
                    <li>灵活性高，易于与其他技术结合，支持多种条件生成任务</li>
                </ul>
                
                <p class="text-gray-700 mb-6 leading-relaxed">
                    扩散模型面临的挑战：
                </p>
                
                <ul class="list-disc list-inside space-y-2 text-gray-700 mb-6 ml-2">
                    <li>采样速度慢，需要大量步骤才能生成样本</li>
                    <li>计算成本高，训练和推理需要大量计算资源</li>
                    <li>理论理解相对复杂，参数调优难度较大</li>
                </ul>
                
                <h3 class="text-xl font-semibold mb-4 text-dark">6.3 未来研究方向</h3>
                
                <p class="text-gray-700 mb-4 leading-relaxed">
                    结合VAE和扩散模型的研究经验，未来生成模型的发展可能集中在以下方向：
                </p>
                
                <div class="bg-gradient-to-r from-purple-50 to-indigo-50 p-6 rounded-lg border border-purple-100 mb-6">
                    <ol class="list-decimal list-inside space-y-3 text-gray-700">
                        <li><strong>效率提升</strong>：开发更高效的采样算法，在保持生成质量的同时减少计算成本</li>
                        <li><strong>理论融合</strong>：进一步探索不同生成模型之间的理论联系，开发兼具多种模型优势的新框架</li>
                        <li><strong>可控生成</strong>：增强生成过程的可控性，实现更精细的生成内容控制</li>
                        <li><strong>多模态生成</strong>：扩展生成模型到更多模态，实现跨模态生成和转换</li>
                        <li><strong>小数据学习</strong>：研究在有限数据下训练高质量生成模型的方法</li>
                    </ol>
                </div>
                
                <p class="text-gray-700 leading-relaxed">
                    无论是VAE还是扩散模型，它们的发展都推动了生成式AI领域的进步。随着研究的深入，我们有理由相信未来会出现更强大、更高效、更易用的生成模型，为人工智能的应用开辟新的可能性。
                </p>
            </section>

            <!-- 参考文献 -->
            <section class="section-fade">
                <div class="flex items-center mb-6">
                    <div class="w-10 h-10 rounded-full bg-primary/10 flex items-center justify-center mr-4">
                        <i class="fa fa-book text-primary"></i>
                    </div>
                    <h2 class="text-3xl font-bold text-dark">参考文献</h2>
                </div>
                
                <ul class="space-y-4 text-gray-700 mb-6 list-decimal list-inside">
                    <li>
                        Kingma, D. P., & Welling, M. (2013). Auto-encoding variational bayes. <em>International Conference on Learning Representations</em>.
                    </li>
                    <li>
                        Kingma, D. P., Rezende, D. J., Mohamed, S., & Welling, M. (2014). Semi-supervised learning with deep generative models. <em>Neural Information Processing Systems</em>.
                    </li>
                    <li>
                        Ho, J., Jain, A., & Abbeel, P. (2020). Denoising diffusion probabilistic models. <em>Neural Information Processing Systems</em>.
                    </li>
                    <li>
                        Rombach, R., Blattmann, A., Lorenz, D., Esser, P., & Ommer, B. (2022). High-resolution image synthesis with latent diffusion models. <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>.
                    </li>
                    <li>
                        Alemi, A. A., Poole, B., Fischer, I., Dillon, J. V., Saurous, R. A., & Murphy, K. (2017). Deep variational information bottleneck. <em>International Conference on Learning Representations</em>.
                    </li>
                    <li>
                        Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., & Ganguli, S. (2015). Deep unsupervised learning using nonequilibrium thermodynamics. <em>International Conference on Machine Learning</em>.
                    </li>
                </ul>
            </section>
        </div>
    </main>

    <!-- 页脚 -->
    <footer class="bg-dark text-gray-300 py-12 mt-16">
        <div class="container mx-auto px-4">
            <div class="max-w-4xl mx-auto">
                <div class="flex flex-col md:flex-row justify-between items-center mb-8">
                    <div class="flex items-center mb-6 md:mb-0">
                        <i class="fa fa-cube text-primary text-2xl mr-2"></i>
                        <h2 class="text-xl font-bold text-white">VAE与扩散模型</h2>
                    </div>
                    <div class="flex space-x-4">
                        <a href="#" class="text-gray-400 hover:text-primary transition-colors">
                            <i class="fa fa-github text-xl"></i>
                        </a>
                        <a href="#" class="text-gray-400 hover:text-primary transition-colors">
                            <i class="fa fa-twitter text-xl"></i>
                        </a>
                        <a href="#" class="text-gray-400 hover:text-primary transition-colors">
                            <i class="fa fa-linkedin text-xl"></i>
                        </a>
                    </div>
                </div>
                
                <div class="border-t border-gray-700 pt-8 text-center text-sm text-gray-400">
                    <p>© 2023 AI技术博客. 保留所有权利.</p>
                    <p class="mt-2">本文档仅供学习参考，转载请注明出处.</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- 返回顶部按钮 -->
    <button id="backToTop" class="fixed bottom-6 right-6 bg-primary text-white w-12 h-12 rounded-full flex items-center justify-center shadow-lg opacity-0 invisible transition-all duration-300 hover:bg-primary/90">
        <i class="fa fa-arrow-up"></i>
    </button>

    <!-- JavaScript -->
    <script>
        // 移动端菜单切换
        const menuBtn = document.getElementById('menuBtn');
        const mobileMenu = document.getElementById('mobileMenu');
        
        menuBtn.addEventListener('click', () => {
            mobileMenu.classList.toggle('hidden');
        });
        
        // 平滑滚动
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                
                // 关闭移动菜单（如果打开）
                if (!mobileMenu.classList.contains('hidden')) {
                    mobileMenu.classList.add('hidden');
                }
                
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
            });
        });
        
        // 返回顶部按钮
        const backToTopBtn = document.getElementById('backToTop');
        
        window.addEventListener('scroll', () => {
            if (window.scrollY > 300) {
                backToTopBtn.classList.remove('opacity-0', 'invisible');
                backToTopBtn.classList.add('opacity-100', 'visible');
            } else {
                backToTopBtn.classList.remove('opacity-100', 'visible');
                backToTopBtn.classList.add('opacity-0', 'invisible');
            }
            
            // 导航栏滚动效果
            const header = document.querySelector('header');
            if (window.scrollY > 100) {
                header.classList.add('py-2', 'shadow');
                header.classList.remove('py-4');
            } else {
                header.classList.add('py-4');
                header.classList.remove('py-2', 'shadow');
            }
            
            // 滚动动画
            const sections = document.querySelectorAll('.section-fade');
            sections.forEach(section => {
                const sectionTop = section.getBoundingClientRect().top;
                const windowHeight = window.innerHeight;
                
                if (sectionTop < windowHeight * 0.75) {
                    section.classList.add('section-visible');
                }
            });
        });
        
        backToTopBtn.addEventListener('click', () => {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });
        
        // 模型关系图表
        const relCtx = document.getElementById('modelRelationshipChart').getContext('2d');
        const modelChart = new Chart(relCtx, {
            type: 'radar',
            data: {
                labels: [
                    '生成质量',
                    '采样速度',
                    '训练稳定性',
                    '潜在空间质量',
                    '计算效率',
                    '灵活性'
                ],
                datasets: [
                    {
                        label: 'VAE',
                        data: [60, 90, 80, 90, 85, 70],
                        fill: true,
                        backgroundColor: 'rgba(139, 92, 246, 0.2)',
                        borderColor: 'rgba(139, 92, 246, 1)',
                        pointBackgroundColor: 'rgba(139, 92, 246, 1)',
                        pointBorderColor: '#fff',
                        pointHoverBackgroundColor: '#fff',
                        pointHoverBorderColor: 'rgba(139, 92, 246, 1)'
                    },
                    {
                        label: '扩散模型',
                        data: [95, 40, 90, 60, 50, 90],
                        fill: true,
                        backgroundColor: 'rgba(59, 130, 246, 0.2)',
                        borderColor: 'rgba(59, 130, 246, 1)',
                        pointBackgroundColor: 'rgba(59, 130, 246, 1)',
                        pointBorderColor: '#fff',
                        pointHoverBackgroundColor: '#fff',
                        pointHoverBorderColor: 'rgba(59, 130, 246, 1)'
                    }
                ]
            },
            options: {
                elements: {
                    line: {
                        borderWidth: 3
                    }
                },
                scales: {
                    r: {
                        angleLines: {
                            display: true
                        },
                        suggestedMin: 0,
                        suggestedMax: 100
                    }
                },
                plugins: {
                    title: {
                        display: true,
                        text: 'VAE与扩散模型各维度表现对比'
                    }
                }
            }
        });
        
        // 页面加载时触发一次滚动检查，以显示初始可见的部分
        window.addEventListener('load', () => {
            window.dispatchEvent(new Event('scroll'));
        });
    </script>
</body>
</html>
